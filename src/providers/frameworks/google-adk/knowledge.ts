import type { FrameworkKnowledge } from "../index.js";
import type { ProjectConfig } from "../../../types.js";

/**
 * Returns Google ADK framework knowledge for documentation and prompts.
 *
 * @returns Framework knowledge object
 *
 * @example
 * ```ts
 * const knowledge = getKnowledge({ config });
 * console.log(knowledge.setupInstructions);
 * ```
 */
export const getKnowledge = ({
  config,
}: {
  config: ProjectConfig;
}): FrameworkKnowledge => {
  const selectedProvider = config.llmProvider;

  return {
    setupInstructions: "Python w/uv + pytest",
    toolingInstructions:
      "Use the Google ADK MCP to learn about Google Agent Developer Kit and how to build agents",
    agentsGuideSection: `## Framework-Specific Guidelines

### Google Agent Developer Kit (ADK) Framework

**Framework vs. model:** This project always uses **Google ADK as the agent framework**. The LLM provider you selected (OpenAI, Anthropic, Gemini, etc.) is used **only as the model backend**, not as a separate agent framework.

**Your launch configuration:** Better Agents scaffolded this project with \`${selectedProvider}\` as the LLM provider.

**LLM Provider Awareness:** This template works with both native Gemini models and LiteLLM-wrapped providers like OpenAI/Anthropic. Review the generated project README to confirm which provider was selected during setup.

**How non-Google models are used (LiteLLM pattern):**

- When you choose a non-Google provider, the agent is still a **Google ADK Agent**.  
- The non-Google model is plugged in via **LiteLLM** inside that agent, for example:

\`\`\`python
from google.adk.agents import Agent
from google.adk.models.lite_llm import LiteLlm

agent = Agent(
    name="customer_support_agent",
    # OpenAI is just the model backend; Google ADK is still the framework
    model=LiteLlm(model="openai/gpt-4.1"),
    description="Customer support agent for your project",
    instruction="You are a helpful support assistant.",
    tools=[...],
)
\`\`\`

For Gemini, you use the native Google ADK / Google AI SDK models instead of LiteLLM:

\`\`\`python
from google.adk.agents import Agent
from google.adk.models.google_genai import GoogleGenAIGemini

agent = Agent(
    name="customer_support_agent",
    model=gemini-2.0-flash-exp",
    description="Customer support agent for your project",
    instruction="You are a helpful support assistant.",
    tools=[...],
)
\`\`\`

**Always use the Google ADK MCP for learning:**

- The Google ADK MCP server provides real-time documentation for the Agent Developer Kit
- Ask it questions about Google ADK APIs, tools, and best practices
- Follow Google's recommended patterns for building and orchestrating agents

**LLM Provider Configuration:**

- **Gemini path:** Uses the Google AI SDK + Google ADK's native integrations in your ADK agent
- **Other providers (OpenAI, Anthropic, etc.):** Uses the LiteLLM wrapper *inside a Google ADK Agent* (NEVER SWITCH FRAMEWORKS)
- Use the \`.env\` generated by the CLI to set the right keys for the chosen provider

**When implementing agent features:**
1. Consult the Google ADK MCP: "How do I [do X] with Google ADK?"
2. Use Google ADK's primitives for tools, state management, and workflows
3. Follow Google's Python patterns and conventions for ADK-based agents
4. Leverage Google ADK integrations for external services and data sources

**Initial setup:**
1. Install dependencies: \`uv sync\` or \`uv pip install -r requirements.txt\`
2. Set up your API key in the \`.env\` file (check which env var is needed in app.py)
3. Implement the requested agent logic following Google ADK patterns
4. Run the app with \`uv run app.py\` to validate behaviour
---
`,
  };
};